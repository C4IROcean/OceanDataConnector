{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mission\n",
    "In this notebook our aim is to create a coral blaching predictor based on time-series data for a specific geographical region.\n",
    "1) The first part concentrates on using geospatial libraries and a library for mulitdimensional data - xarray. Here you will learn how to manipulate Sea Surface Temperature data using xarray. Here you will also learn how to visualize the data. \n",
    "\n",
    "2) The second part will load a pre-trained model to make predictions in areas where bleaching data is not available. The predictions are made using the timeseries data in the first part. \n",
    "\n",
    "### Libraries\n",
    "Libraries that you should have a glance at  \n",
    "* odp - [The Ocean data Platfrom SDK](https://odp-sdk-python.readthedocs.io/en/master/)\n",
    "* geopandas - [Geopandas](https://geopandas.org/en/stable/getting_started/introduction.html)\n",
    "* xarray - [Xarray](https://docs.xarray.dev/en/stable/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to pip install tensorflow for the second part of ths notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import json\n",
    "import xarray as xr\n",
    "\n",
    "import odp.geospatial as odp\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.dates as md\n",
    "import dateutil\n",
    "import numpy as np\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "import cartopy.feature as cfeature\n",
    "import cmocean\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "from math import pi, sqrt\n",
    "import pickle\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from azure.storage.blob import ContainerClient\n",
    "import zarr\n",
    "import altair as alt\n",
    "import hvplot.xarray\n",
    "import cmocean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the Ocean data platform database\n",
    "db = odp.Database()\n",
    "# instantiate plotting tools\n",
    "db_plt = odp.PlotTools()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving time series data for Sea Surface Temp\n",
    "Necessary code to connect to Azure storage to retrieve timeseries for Sea Surface Temperature. This is data import broiler plate - you do not have to understand what is going on here to finish the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container_client = ContainerClient.from_container_url(\n",
    "    container_url=\"https://stodpdaskuserspace.blob.core.windows.net/crw\",\n",
    "    credential=os.environ[\"ODE_CRW_TOKEN\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = \"crw\"\n",
    "folder = \"zarr/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = list(\n",
    "    set([b.name for b in container_client.walk_blobs(folder, delimiter=\"/\")])\n",
    ")\n",
    "file_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "store_list = []\n",
    "for year in range(1985, 2023):\n",
    "    result = list(filter(lambda x: \"_\" + str(year) + \"_\" in x, file_list))\n",
    "    for file in result:\n",
    "        store = zarr.ABSStore(prefix=file, client=container_client)\n",
    "        store_list.append(store)\n",
    "temp_data = xr.open_mfdataset(store_list, parallel=True, engine=\"zarr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The oupt is an [xarray](https://docs.xarray.dev/en/stable/) dataset which is a multi-dimensional, in memory, array database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the polygon of Florida and Northern Caribbean using geopandas\n",
    "As most of our data is in the Florida and Northern Caribbean region we have decided to concentrate on this area. We have create a premade geojson file containing the coordinates a the drawn polygon that represents the area. \n",
    "\n",
    "You can feel free to create your own bounding box and explore temperatures in those areas if you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = gpd.read_file(\"boundary.geojson\")\n",
    "poly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly[\"geometry\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure out the bounding box for our area of interest\n",
    "A bounding box is the smallest rectangle that contains all of the given points in the selected region.<br>Since our temperature data has information on what region the temperature is measured in we want to make sure that we only select data from that specific area. <br>In order to do this we need to find the boundrary coordinates for the area.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = list(poly[\"geometry\"][0].envelope.exterior.coords)\n",
    "coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a slice of the temperature data only for the area we care about (the bounding box we created)\n",
    "xarray has a built in slicing tool that allows us to take just a slice of all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_slice = temp_data.sel(\n",
    "    lon=slice(coords[0][0], coords[1][0]), lat=slice(coords[0][1], coords[2][1])\n",
    ")\n",
    "ds_slice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's take a look at 2005, a year with a lot of coral bleaching in the caribbean\n",
    "Again, xarray has built-in functionality that allows you to take a specific time slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_2005 = ds_slice.isel(time=(ds_slice.time.dt.year == 2005))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With built in xarray functions we can easily visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_means = ds_2005.groupby(\"time.month\").mean()\n",
    "fg = monthly_means.analysed_sst.plot(\n",
    "    col=\"month\",\n",
    "    col_wrap=4,\n",
    "    cmap=cmocean.cm.thermal,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And even see it play over time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_2005.hvplot(\n",
    "    groupby=\"time\",\n",
    "    clim=(15, 35),\n",
    "    widget_type=\"scrubber\",\n",
    "    widget_location=\"bottom\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "What observations can we draw from the data visualizations over the course of a year?\n",
    "<br>Can we compare the same data from different years to see how they differ?\n",
    "<br>In 2010, the florida keys had a severe cold front that resulted in major coral death. Can this be seen through this data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can also turn the xarray into a pandas dataframe that more people are familiar with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by taking a small subset of the xarray to seeed up our processing. Then we will split the datetime object from the xarray into sepearate time columns so that we easily can filter the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_slice = temp_data.sel(\n",
    "    lon=slice(-80, -78), lat=slice(20, 22), time=slice(\"1990-01-01\", \"2022-01-01\")\n",
    ")\n",
    "ds_slice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next step takes a bit (around 5 mins), might be a good time to grab a coffee, or check out this really [cool google earth site about coral bleaching!](https://earth.google.com/web/@24.4430141,123.8161774,-0.51676057a,500d,35y,10.51093386h,0t,0r/data=CkoSSBIgY2EwYzk0ZGNhN2I4MTFlN2I1ZDBiNzRhMWFlNGU2MDMiJGVmZWVkX29jZWFuX2FnZW5jeV9jb3JhbF9ibGVhY2hpbmdfMQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = (\n",
    "    ds_slice.to_dataframe().reset_index()\n",
    ")  ## This can take some time depending on size of slice\n",
    "df[\"time\"] = pd.to_datetime(df[\"time\"], format=\"%m/%d/%y %I:%M%p\")\n",
    "df[\"mnth_yr\"] = df.time.dt.to_period(\"M\").astype(str)\n",
    "df[\"year\"] = df.time.dt.year.astype(str)\n",
    "df[\"month\"] = df.time.dt.month.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_by_mnth_yr_df = (\n",
    "    df.groupby([\"mnth_yr\", \"year\", \"month\"])\n",
    "    .agg({\"analysed_sst\": [\"mean\", \"min\", \"max\"]})\n",
    "    .reset_index()\n",
    ")\n",
    "temp_by_mnth_yr_df.columns = [\"mnth_yr\", \"year\", \"month\", \"mean\", \"min\", \"max\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_by_mnth_yr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a plot with a dataframe requires some more code, here we create a chart that displays the montly mean temprature and the average temprature per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = alt.selection_multi(fields=[\"year\"], bind=\"legend\")\n",
    "chart = (\n",
    "    alt.Chart(temp_by_mnth_yr_df)\n",
    "    .mark_line()\n",
    "    .encode(\n",
    "        x=alt.X(\"month\", title=\"Month\", sort=\"ascending\"),\n",
    "        y=alt.Y(\n",
    "            \"mean\", title=\"Monthly mean temperature\", scale=alt.Scale(domain=(22, 33))\n",
    "        ),\n",
    "        color=alt.Color(\n",
    "            \"year\",\n",
    "            title=\"Year\",\n",
    "            scale=alt.Scale(\n",
    "                domain=temp_by_mnth_yr_df[\"year\"].unique(), scheme=\"paired\"\n",
    "            ),\n",
    "        ),\n",
    "        opacity=alt.condition(selection, alt.value(1), alt.value(0.2)),\n",
    "        # tooltip=[alt.Tooltip('mean', title='Mean Temperature')],\n",
    "        tooltip=[\"mean\", \"year\"],\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "line = (\n",
    "    alt.Chart(pd.DataFrame({\"mean\": [30.5]}))\n",
    "    .mark_rule()\n",
    "    .encode(y=\"mean\", color=alt.value(\"#FF0000\"), strokeWidth=alt.value(3))\n",
    ")\n",
    "\n",
    "alt.layer(chart, line).configure_view(stroke=\"transparent\").properties(\n",
    "    title=\"Monthly average per year\", width=500, height=300\n",
    ").configure_axis(labelFontSize=15, titleFontSize=15).configure_legend(\n",
    "    labelFontSize=12, columns=1, labelLimit=500, symbolLimit=100\n",
    ").add_selection(\n",
    "    selection\n",
    ").add_selection(\n",
    "    selection\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at a specific year and add a visual check if the temperature is above 30.5 degrees - an important treshold for corals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = temp_by_mnth_yr_df[temp_by_mnth_yr_df.year == \"2005\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "\n",
    "\n",
    "plt.plot(df_plot['mnth_yr'],df_plot['mean'], 'g')\n",
    "plt.axhline(y =30.5, color = 'r', linestyle = '--')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.scatter(df_plot['mnth_yr'],df_plot['mean'],c='g',label='mean temp')\n",
    "\n",
    "\n",
    "plt.xlabel('mnth_yr',size=14)\n",
    "plt.ylabel('temperature($^\\circ C$ )',size=14)\n",
    "plt.xticks(rotation = 45)\n",
    "plt.xticks(df_plot['mnth_yr'])\n",
    "ax=plt.gca()\n",
    "ax.axis([0,11,-40,40])\n",
    "plt.title('Mean temperature',size=14)\n",
    "plt.legend(loc=0)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we also have information on the max and min temps, we can create boundaraies to better understand the temprature deviation for a month. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "\n",
    "plt.plot(df_plot[\"mnth_yr\"], df_plot[\"max\"], \"--r\")\n",
    "plt.plot(df_plot[\"mnth_yr\"], df_plot[\"min\"], \"-.b\")\n",
    "plt.plot(df_plot[\"mnth_yr\"], df_plot[\"mean\"], \"g\")\n",
    "plt.scatter(df_plot[\"mnth_yr\"], df_plot[\"max\"], c=\"r\", label=\"max temp\")\n",
    "plt.scatter(df_plot[\"mnth_yr\"], df_plot[\"min\"], c=\"b\", label=\"min temp\")\n",
    "plt.scatter(df_plot[\"mnth_yr\"], df_plot[\"mean\"], c=\"g\", label=\"mean temp\")\n",
    "\n",
    "plt.xlabel(\"mnth_yr\", size=14)\n",
    "plt.ylabel(\"temperature($^\\circ C$ )\", size=14)\n",
    "plt.xticks(rotation=45)\n",
    "plt.xticks(df_plot[\"mnth_yr\"])\n",
    "ax = plt.gca()\n",
    "plt.gca().fill_between(\n",
    "    df_plot[\"mnth_yr\"], df_plot[\"max\"], df_plot[\"min\"], facecolor=\"#9D59F4\", alpha=0.35\n",
    ")\n",
    "plt.title(\"Maximum, minimum and mean temperature\", size=14)\n",
    "plt.legend(loc=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge\n",
    "Grouping this giant area together is taking quite some liberties and is not the best way to represent the data. Pick a more granular area and look at the trends. (Below there is some information or specific coral reef sites)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's try to combine temperature data with coral bleaching data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read the bleaching data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bl = pd.read_csv(\"bleaching_data.csv\")\n",
    "df_bl[\"longitude\"] = df_bl.Longitude_Degrees.round()\n",
    "df_bl[\"latitude\"] = df_bl.Latitude_Degrees.round()\n",
    "\n",
    "df_bl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frist we want to look at what year contains the most data on bleaching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bl[[\"Date_Year\", \"Bleaching_Level\"]].groupby(\"Date_Year\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geopandas is a powerful library to use when working with data that contains geographical information. Lets convert the coral bleaching dataframe from above to a GeoDataFrame object\n",
    "This will create a 'geometry' column that is easy to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.GeoDataFrame(\n",
    "    df_bl, geometry=gpd.points_from_xy(df_bl.Longitude_Degrees, df_bl.Latitude_Degrees)\n",
    ")\n",
    "gdf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot bleaching samples by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_plt.plot_points(gdf, col=\"Date_Year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot bleaching samples by Bleaching Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_plt.plot_points(gdf.where(gdf[\"Bleaching_Level\"] > 0), col=\"Bleaching_Level\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge\n",
    "\n",
    "Plot another column that could be an intersting feature to look closer at."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Timeseries classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "As seen in the plots from the bleaching database, there are areas without any samples.<br>\n",
    "In this section we are using a pre-trained binary classification model to predict if \n",
    "an area has bleached corals based on the sea surface temperatue timeseries of the areas locations.<br>\n",
    "Creating and training the model is not part of this workshop, but if you would like to see how it was done and/or further improve it after the workshop, \n",
    "the code is in a notebook called `timeseries_classification.ipynb`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting sea surface temperature timeseries for an area without samples in the bleaching database\n",
    "ds_slice_predict = temp_data.sel(\n",
    "    lon=slice(-80, -75), lat=slice(18, 22), time=slice(\"2000-01-01\", \"2020-01-05\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this next step takes a bit (around 5 mins), might be a good time to grab a coffee, or check out this really [cool google earth site about coral bleaching!](https://earth.google.com/web/@24.4430141,123.8161774,-0.51676057a,500d,35y,10.51093386h,0t,0r/data=CkoSSBIgY2EwYzk0ZGNhN2I4MTFlN2I1ZDBiNzRhMWFlNGU2MDMiJGVmZWVkX29jZWFuX2FnZW5jeV9jb3JhbF9ibGVhY2hpbmdfMQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df = ds_slice_predict.to_dataframe().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of sea surface temperature readings for all locations (lat-lon group)\n",
    "df[\"analysed_sst\"] = df[\"analysed_sst\"].fillna(0)\n",
    "df_grp = df.groupby(by=[\"lat\", \"lon\"]).agg({\"analysed_sst\": lambda x: list(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove locations where all the temperatures are NaN or 0\n",
    "df_grp[\"sst_sum\"] = df_grp.apply(lambda row: sum(row[\"analysed_sst\"]), axis=1)\n",
    "df_grp = df_grp.where(df_grp[\"sst_sum\"] > 0).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale the temperatures\n",
    "Input variables should be normalized to have a normal distribution, since most ML models assume this of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the same sklearn StandardScaler as used when training the model\n",
    "scaler = pickle.load(open(\"scaler.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_scaler(data_list):\n",
    "    scaled_array = scaler.transform(np.array(data_list).reshape(-1, 1))\n",
    "    return scaled_array.reshape(scaled_array.shape[0]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the all the temeratures in the list\n",
    "df_grp[\"sst_scaled\"] = df_grp.apply(\n",
    "    lambda row: data_scaler(row[\"analysed_sst\"]), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import/install tensorflow and load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "#!{sys.executable} -m pip install tensorflow\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.models.load_model(\"./ts_classification_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use model to predict whether corals on location are bleached or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_predict(data_list):\n",
    "    x_array = np.array(data_list[3000:7000]).reshape(1, 4000, 1)\n",
    "    y_pred = model.predict(np.array(x_array))\n",
    "    return np.argmax(y_pred, axis=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This step also takes a few minutes\n",
    "df_grp[\"bleached_predict\"] = df_grp.apply(\n",
    "    lambda row: data_predict(row[\"sst_scaled\"]), axis=1\n",
    ")  # This takes some time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grp_l = df_grp.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grp_geo = gpd.GeoDataFrame(\n",
    "    df_grp_l, geometry=gpd.points_from_xy(df_grp_l[\"lon\"], df_grp_l[\"lat\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the predictions on a map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows locations (betweeen South Cuba and North Jamacia) where corals are predicted to be bleached (1, dark color) and not bleached (0, yellow color).\n",
    "Not all locations have coral reefs, this is not taken into considerations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_plt.plot_points(df_grp_geo, col=\"bleached_predict\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did you learn with this notebook?<br>\n",
    "What else could be done with this data?<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
